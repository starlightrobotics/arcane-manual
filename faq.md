# Frequently Asked Questions


1. **Do I need GPU?** - You do not need GPU to run LLMs. You can run them on CPU + Equivalent RAM. GPU makes models run faster.

2. **GGUF vs GGML?** - GGUF is positioned as an upgrade to GGML, offering more flexibility, extensibility, and compatibility. It aims to simplify the user experience and accommodate various models beyond llama. cpp. GGML, while a valuable early effort, had limitations that GGUF seeks to overcome.

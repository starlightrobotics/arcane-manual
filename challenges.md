# Challenges for LLM development and adoption

## What we need in LLMs
* **Faster and Cheaper LLMs** - an ongoing field of optimisation and improvement. in 2023-2024 the jump in scale and improvement of quality is stunning.
* **More context size for local models** - many models are reported to have larger context window, but they fail to actually use it.
* **Better long-term memory**
* **Better character preservation** - over time as the conversation carries on, the character sheet needs to be re-injected into the conversation, to refresh the behaviour.
* **Better logic** - LLMs are language models, not logic models. They write text well and they are fascinating about how much they can do, but are not explicitly designed for logical tasks.

## LoRAs and Finetunes
* many loras are compatible only with a specific model.
* Fine-tunes sometimes break the quality of the base model
